{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "443a50ff-d105-4a10-9363-050725fe21df",
   "metadata": {},
   "source": [
    "# Serialising both weights and hyperparameters\n",
    "\n",
    "Equinox has [facilities](/equinox/api/utilities/serialisation/) for the serialisation of the leaves of arbitrary PyTrees. The most basic use is to call `eqx.tree_serialise_leaves(filename, model)` to write all weights to a file. Deserialisation requires a PyTree of the correct shape to serve as a \"skeleton\" of sorts, whose weights are then read from the file with `model = eqx.tree_deserialise_leaves(filename, skeleton)`.\n",
    "\n",
    "In practice this is not quite what we want. A typical model has both weights (arrays stored as leaves in the PyTree) and hyperparameters (determining, among other things, the shapes of those arrays). When deserialising, we would like to read the hyperparameters as well as the weights. Ideally they are stored in the same file, to minimize the chance of error. With only a little more work, we can accomplish just this, in a structured way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a0bae8-2435-4b37-b1f2-24322cfeb1dd",
   "metadata": {},
   "source": [
    "To be concrete, let's import everything and set up a simple model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83bba892-5425-4eed-a7f7-9c325fe5cc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import equinox as eqx\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "\n",
    "def make(*, key, size, width, depth, use_tanh=False):\n",
    "    if use_tanh:\n",
    "        activation = jnp.tanh\n",
    "    else:\n",
    "        activation = jax.nn.relu\n",
    "    # (This is not meant to be a realistically useful model.)\n",
    "    return eqx.nn.MLP(\n",
    "        in_size = size,\n",
    "        out_size = 1,\n",
    "        width_size = width,\n",
    "        depth = depth,\n",
    "        activation = activation,\n",
    "        key = key\n",
    "    )\n",
    "    \n",
    "hyperparameters = {\n",
    "    'size': 5,\n",
    "    'width': 10,\n",
    "    'depth': 3,\n",
    "    'use_tanh': True\n",
    "}\n",
    "model = make(key=jr.PRNGKey(0), **hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb345b0-c9b3-44df-94e8-d74c7ad172b8",
   "metadata": {},
   "source": [
    "At this point, we haven't just created a model, but defined a function that allows us to re-create a model of the same structure. Additionally, the hyperparameters used to create `model` have been saved for later serialisation.\n",
    "\n",
    "We may now train the model as usual. When the time comes to serialise, we want to put both hyperparameters and leaves in the same file. This is accomplished like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fd94db04-9fe4-4530-808e-945becef9df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(filename, params, model):\n",
    "    with open(filename, \"wb\") as f:\n",
    "        param_str = json.dumps(params)\n",
    "        f.write((param_str+\"\\n\").encode())\n",
    "        eqx.tree_serialise_leaves(f, model)\n",
    "    \n",
    "save(\"multipart_serialised.eqx\", hyperparameters, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da180e54-0deb-4e33-be7b-9856049cd483",
   "metadata": {},
   "source": [
    "We've been a bit slick here. A single file now contains a valid json expression storing the hyperparameters and, after a newline, the bytes serialising the weights in our model. Implicitly we're relying on the fact that python's built-in json serialisation places everything on a single line.\n",
    "\n",
    "With the hyperparameters and model serialised in this way, deserialisation occurs in three steps:\n",
    "1. Read the first line from the file, and parse the json into a dictionary.\n",
    "2. Construct a skeleton model using `make()`.\n",
    "3. Have equinox deserialise the remainder of the file, using the skeleton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "32c6b58e-f72f-4dd4-bf2c-f1dc75643eda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        params = json.loads(f.readline().decode())\n",
    "        make(key=jr.PRNGKey(0), **params)\n",
    "        return eqx.tree_deserialise_leaves(f, model)\n",
    "\n",
    "newmodel = load(\"multipart_serialised.eqx\")\n",
    "\n",
    "# Check that it's loaded correctly:\n",
    "assert model.layers[1].weight[2,2] == newmodel.layers[1].weight[2,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee431d2-41f4-4e96-89f2-47e239d92574",
   "metadata": {},
   "source": [
    "**Miscellaneous notes**\n",
    "\n",
    "* Many variations are possible. Bear in mind: equinox serialisation doesn't have to write to a file. You can write to any compatible buffer, e.g. an `io.BytesIO` object.\n",
    "* If using batch normalisation or similar, do not forget to set the appropriate inference flag when loading. It may be best to make this a required argument to `make()`.\n",
    "\n",
    "**Why not `pickle`?**\n",
    "\n",
    "The `pickle` module is python's go-to for all-purpose serialisation. Why didn't we just use that?\n",
    "\n",
    "First, `equinox` modules make rich use of lambda expressions, which can't be pickled. This makes pickling unusable even for casual experiments. This can potentially be cured by using another package (e.g. [`dill`](https://pypi.org/project/dill/)).\n",
    "\n",
    "That brings us to the two more serious, and related, problems (at least for production-level projects): the pickle format changes from time to time, unpickling loads and runs arbitrary code. We all expect a file named `*.py` to be potentially malicious, but a file ostensibly containing \"just floating-point numbers\" should be safe to use from an untrusted source. The methods described above allow weights to be shared safely as long as the underlying model code is trusted; the serialised file really is interpreted as just an array of numbers.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
